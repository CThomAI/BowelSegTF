{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: \n",
    "# import of PET\n",
    "# alignment of CT and BBprediction with PET\n",
    "# PET conversion to SUVbw\n",
    "\n",
    "# v2.1\n",
    "# uses latest BB prediction model:\n",
    "#\"30ptsChris_3D_ExtendedSlicesWithBB_Unet_3level_5conv_16slice_BCE_LRe-4_systematic_order_500_ValLoss_best_mdl_wts\"\n",
    "# extracts SUV data from BB prediction\n",
    "\n",
    "#v2.2\n",
    "# incorporates largest 3D connected component\n",
    "\n",
    "#v2.3GUIprep\n",
    "# incorporates removal of peripheral PET uptake that amounts to bladder/kidneys/liver etc. \n",
    "# started gathering some stats at the end (min, max, mean, percentiles etc).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt, cm\n",
    "from matplotlib import image\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##required for the scrollable image viewer\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom\n",
    "import dicom_numpy\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import flip\n",
    "import nibabel as nib\n",
    "import math\n",
    "import datetime\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import nibabel as nib\n",
    "import math\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, model_from_json, load_model\n",
    "# from keras.layers import Input, Dropout, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose\n",
    "from keras.layers import Input, Dropout, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, concatenate, Conv2DTranspose, Conv3DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "K.set_image_dim_ordering('th')  # Theano dimension ordering in this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and prep CTpet and PET data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #user defines location of the CT DICOM files\n",
    "# baseCT = \"D:/CNNdata/Bowel_Segmentation/RATHL_Data_Validation/CT\"\n",
    "# basePET = \"D:/CNNdata/Bowel_Segmentation/RATHL_Data_Validation/PT\"\n",
    "# ID = 1\n",
    "\n",
    "baseCT = \"D:/CNNdata/Bowel_Segmentation/RATHL_Data_Validation/CT\"\n",
    "basePET = \"D:/CNNdata/Bowel_Segmentation/RATHL_Data_Validation/PT\"\n",
    "ID = \"5\"\n",
    "## User will define the sup and inf limits of bowelbag prediction - probably from GUI\n",
    "## as slice number from inf end in normal numbering i.e. from 1\n",
    "## and the slice position then calculated later from b_CT\n",
    "BBinfSliceNo = 62 # in normal numbering i.e. from 1\n",
    "BBsupSliceNo = 157 # in normal numbering i.e. from 1\n",
    "\n",
    "PathDicomCT = os.path.join(str(baseCT) + str(ID))\n",
    "PathDicomPET = os.path.join(str(basePET) + str(ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract voxel data from DICOM to Numpy using the dicom_numpy module\n",
    "# seems to take into account the rescale intercept appropriately\n",
    "\n",
    "def extract_voxel_data(list_of_dicom_files):\n",
    "    datasets = [dicom.read_file(f) for f in list_of_dicom_files]\n",
    "    try:\n",
    "        voxel_ndarray, ijk_to_xyz = dicom_numpy.combine_slices(datasets)\n",
    "    except dicom_numpy.DicomImportException as e:\n",
    "        # invalid DICOM data\n",
    "        raise\n",
    "    return voxel_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the list of DICOM files in the CT and PET folders\n",
    "\n",
    "def listofDICOMfiles():\n",
    "    \n",
    "    global lstFilesDCM_CT\n",
    "    global lstFilesDCM_PET\n",
    "\n",
    "    lstFilesDCM_CT = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicomCT):\n",
    "        for filename in fileList:\n",
    "            if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM_CT.append(os.path.join(dirName,filename))\n",
    "\n",
    "    lstFilesDCM_PET = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicomPET):\n",
    "        for filename in fileList:\n",
    "            if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM_PET.append(os.path.join(dirName,filename)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDicoms():\n",
    "    \n",
    "    global b_CT\n",
    "    global CTarray\n",
    "    global PETarray\n",
    "    global PETReconDiameter\n",
    "    global CTReconDiameter\n",
    "    global ConstPixelDims_CT\n",
    "    global ConstPixelDims_PET\n",
    "    \n",
    "    # Get ref file\n",
    "    RefCT = dicom.read_file(lstFilesDCM_CT[0])\n",
    "    # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
    "    ConstPixelDims_CT = (int(RefCT.Rows), int(RefCT.Columns), len(lstFilesDCM_CT))\n",
    "    # Load spacing values (in mm)\n",
    "    ConstPixelSpacing_CT = (float(RefCT.PixelSpacing[0]), float(RefCT.PixelSpacing[1]), float(RefCT.SliceThickness))\n",
    "    CTReconDiameter = round((RefCT.PixelSpacing[0]) * (RefCT.Rows))\n",
    "    print(\"CTReconDiameter = \", CTReconDiameter)\n",
    "\n",
    "    # Get header info from PET\n",
    "    RefPET = dicom.read_file(lstFilesDCM_PET[0])\n",
    "    # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
    "    ConstPixelDims_PET = (int(RefPET.Rows), int(RefPET.Columns), len(lstFilesDCM_PET))\n",
    "    # Load spacing values (in mm)\n",
    "    ConstPixelSpacing_PET = (float(RefPET.PixelSpacing[0]), float(RefPET.PixelSpacing[1]), float(RefPET.SliceThickness))\n",
    "\n",
    "    PETReconDiameter = round((RefPET.PixelSpacing[0]) * (RefPET.Rows))\n",
    "    print(\"PETReconDiameter = \", PETReconDiameter)\n",
    "    #PETReconDiameter\n",
    "    \n",
    "    # This is needed later to find the slice number of the first slice of BB\n",
    "    # The array is sized based on 'ConstPixelDims'\n",
    "    a_CT = np.zeros(ConstPixelDims_CT[2])\n",
    "    i=0\n",
    "    # loop through all the DICOM files, reading the slice numbers to array\n",
    "    for filenameDCM in lstFilesDCM_CT:\n",
    "        dsCT = dicom.read_file(filenameDCM)\n",
    "        sliceNumber = dsCT.ImagePositionPatient[2]\n",
    "        a_CT[i] = sliceNumber\n",
    "        i=i+1\n",
    "\n",
    "    b_CT = np.sort(a_CT, axis=-1, kind='quicksort', order=None) #element 0 is inf-most slice\n",
    "    #b_CT\n",
    "\n",
    "\n",
    "    # RefCT.SpacingBetweenSlices is what is needed for slice separation\n",
    "    # but for some header files it doesn't appear.\n",
    "    # Therefore backup is to calculate difference between slice positions\n",
    "\n",
    "    try:\n",
    "        d = float(RefCT.SpacingBetweenSlices)\n",
    "\n",
    "    except AttributeError:\n",
    "        # Creating the Big Object takes five days\n",
    "        # and three hundred pounds of over-ripe melons.\n",
    "        d = round(b_CT[1] - b_CT[0],2)\n",
    "\n",
    "    print(d)\n",
    "    \n",
    "    CTarray = extract_voxel_data(lstFilesDCM_CT)\n",
    "    PETarray = extract_voxel_data(lstFilesDCM_PET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArrayMods():\n",
    "    \n",
    "    global CTarray\n",
    "    global PETarray\n",
    "    global TestSlices\n",
    "    global CTarrayNormBBslices\n",
    "    global PETarrayNew\n",
    "    global BBinfSliceNo\n",
    "    global BBsupSliceNo\n",
    "    global Slices\n",
    "    \n",
    "    ## slice position calculated from b_CT\n",
    "    BBinfSlicePos = b_CT[BBinfSliceNo-1]\n",
    "    print(BBinfSlicePos)\n",
    "    BBsupSlicePos = b_CT[BBsupSliceNo-1]\n",
    "    print(BBsupSlicePos)\n",
    "\n",
    "    print(\"CT array shape = \",np.shape(CTarray))\n",
    "    print(\"CT minimum HU = \", np.min(CTarray))\n",
    "\n",
    "    #some CT data has a ring of -3000 values around the FOV circle ... not sure why\n",
    "    CTarray[CTarray < -1000] = -1000\n",
    "\n",
    "    print(\"CT array shape = \",np.shape(CTarray))\n",
    "\n",
    "\n",
    "    CTarray = np.transpose(CTarray, (2,0,1)) \n",
    "    CTarray = np.expand_dims(CTarray, axis=0)\n",
    "    CTarray = np.expand_dims(CTarray, axis=0)\n",
    "\n",
    "    print(\"CT array shape = \",np.shape(CTarray))\n",
    "\n",
    "    CTarray = np.rot90(CTarray,1,(3,4))\n",
    "    # for i in range(0,ConstPixelDims_CT[2]):\n",
    "    #     CTarrayNorm[i,0,:,:] = np.rot90(CTarrayNorm[i,0,:,:],1)\n",
    "\n",
    "    print(\"Replace all elements of CT array with 2000 which are greater than 2000HU\")\n",
    "    print(\"This will set all of the metal to to bone density\")\n",
    "    print(\"Could set it to air or tissue instead I guess but hip implants should be set to bone at least\")\n",
    "    print(\"Performed normalisation\")\n",
    "\n",
    "    HighDens = 2000\n",
    "\n",
    "    CTarray[CTarray > HighDens] = HighDens\n",
    "    CTarrayNorm=(CTarray/(HighDens+1000)) +(1/3)\n",
    "\n",
    "    print(\"PET array shape = \",np.shape(PETarray))\n",
    "\n",
    "    PETarrayNew = np.transpose(PETarray, (2,0,1)) #numbers indicate where the original dimension should go\n",
    "    PETarrayNew = np.expand_dims(PETarrayNew, axis = 0) # adds a dimension\n",
    "    PETarrayNew = np.expand_dims(PETarrayNew, axis = 0) # adds a dimension\n",
    "\n",
    "    PETarrayNew = np.rot90(PETarrayNew,1,(3,4))\n",
    "\n",
    "\n",
    "    print(\"CT array shape =  \", np.shape(CTarrayNorm))\n",
    "    print(\"PET array shape = \",np.shape(PETarrayNew))\n",
    "\n",
    "    Slices = np.size(CTarrayNorm,2)\n",
    "    Slices\n",
    "\n",
    "    CTarrayNormBBslices = CTarrayNorm[:,:,(BBinfSliceNo-1):(BBsupSliceNo),:,:]\n",
    "    TestSlices = np.size(CTarrayNormBBslices,2)\n",
    "    TestSlices\n",
    "\n",
    "    print(\"CTarray BBslices shape = \",np.shape(CTarrayNormBBslices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow setup and model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_3D_3level():  \n",
    "    \n",
    "    #inputs = Input((1, image_rows, image_cols, image_slices))\n",
    "    inputs = Input((1, image_slices, image_rows, image_cols))\n",
    "    #inputs = Input((image_slices, image_rows, image_cols))\n",
    "    \n",
    "    print(np.shape(inputs))\n",
    "    conv1 = Conv3D(32, (5, 5, 5), activation='relu', padding='same')(inputs)\n",
    "    print(np.shape(conv1))\n",
    "    D1=Dropout(0.2)(conv1) #need this?\n",
    "    print(np.shape(D1))\n",
    "    conv1 = Conv3D(32, (5, 5, 5), activation='relu', padding='same')(D1)\n",
    "    print(np.shape(conv1))\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    print(np.shape(pool1))\n",
    "    \n",
    "#     now at 256x256\n",
    "    \n",
    "    conv2 = Conv3D(64, (5, 5, 5), activation='relu', padding='same')(pool1)\n",
    "    print(np.shape(conv2))\n",
    "    D2=Dropout(0.2)(conv2)\n",
    "    print(np.shape(D2))\n",
    "    conv2 = Conv3D(64, (5, 5, 5), activation='relu', padding='same')(D2)\n",
    "    print(np.shape(conv2))\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    print(np.shape(pool2))\n",
    "    \n",
    "#     now at 128x128\n",
    "\n",
    "    conv3 = Conv3D(128, (5, 5, 5), activation='relu', padding='same')(pool2)\n",
    "    print(np.shape(conv3))\n",
    "    D3=Dropout(0.2)(conv3)\n",
    "    print(np.shape(D3))\n",
    "    conv3 = Conv3D(128, (5, 5, 5), activation='relu', padding='same')(D3)\n",
    "    print(np.shape(conv3))\n",
    "    \n",
    "    up9 = concatenate([Conv3DTranspose(64, (2, 2, 2), strides=2, padding='valid')(conv3), conv2], axis=1)\n",
    "    print(np.shape(up9))\n",
    "    conv9 = Conv3D(64, (5, 5, 5), activation='relu', padding='same')(up9)\n",
    "    print(np.shape(conv9))\n",
    "    D9=Dropout(0.2)(conv9)\n",
    "    print(np.shape(D9))\n",
    "    conv9 = Conv3D(64, (5, 5, 5), activation='relu', padding='same')(D9)\n",
    "    print(np.shape(conv9))\n",
    "\n",
    "    up10 = concatenate([Conv3DTranspose(32, (2, 2, 2), strides=2, padding='same')(conv9), conv1], axis=1)\n",
    "    print(np.shape(up10))\n",
    "    conv10 = Conv3D(32, (5, 5, 5), activation='relu', padding='same')(up10)\n",
    "    print(np.shape(conv10))\n",
    "    D10=Dropout(0.2)(conv10)\n",
    "    print(np.shape(D10))\n",
    "    conv10 = Conv3D(32, (5, 5, 5), activation='relu', padding='same')(D10)\n",
    "    print(np.shape(conv10))\n",
    "\n",
    "    conv11 = Conv3D(1, (1, 1, 1), activation='sigmoid')(conv10) \n",
    "    print(np.shape(conv11))\n",
    "\n",
    "    model = Model(input=inputs, output=conv11)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D 3-level Unet - Auto-segment bowelbag on CTpet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadmodel():\n",
    "\n",
    "    global image_rows\n",
    "    global image_cols\n",
    "    global image_slices\n",
    "    global TestSlices\n",
    "    global BatchesPerPt\n",
    "    global batch_size\n",
    "    global model\n",
    "    \n",
    "    #user needs to set this correctly according to the network's design\n",
    "    batch_size = 16\n",
    "\n",
    "    image_rows = 512\n",
    "    image_cols = 512\n",
    "    image_slices = batch_size\n",
    "\n",
    "    model = get_unet_3D_3level()\n",
    "\n",
    "    for i in range (0,TestSlices):\n",
    "        BatchesPerPt = math.ceil(TestSlices / batch_size) # rounds up to work out how many batches from the pt\n",
    "    print(\"batches per patient=\", BatchesPerPt)\n",
    "\n",
    "    # user to enter location of the model\n",
    "    ModelLocation = 'D:/CNNdata/Bowel_Segmentation/Model_Latest/'\n",
    "\n",
    "    # user to enter the name of the model\n",
    "    ModelName = '30ptsChris_3D_ExtendedSlicesWithBB_Unet_3level_5conv_16slice_BCE_LRe-4_systematic_order_500_ValLoss_best_mdl_wts.hdf5'\n",
    "\n",
    "    model.load_weights(os.path.join(str(ModelLocation) + str(ModelName)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictBB():\n",
    "\n",
    "    global BatchesPerPt\n",
    "    global BBpredict\n",
    "\n",
    "                \n",
    "    BBpredict = np.zeros((1,1,TestSlices,512,512), dtype = 'float32')\n",
    "\n",
    "    batch_end_slice = TestSlices -1  # where numslices is an array of number of slices for each patient\n",
    "\n",
    "    for j in range (0,BatchesPerPt):\n",
    "\n",
    "        if j == BatchesPerPt-1: #i.e. if the last batch in that patient, use first \"batch_size\" slices\n",
    "\n",
    "            print(\"batch = \", j)\n",
    "            batch_end_slice = batch_size - 1\n",
    "            batch_start_slice = 0\n",
    "            print(\"start slice = \", batch_start_slice)\n",
    "            print(\"end slice = \", batch_end_slice)\n",
    "            print(\"end slice + 1 = \", batch_end_slice + 1)\n",
    "            BBpredict[0:1,:,batch_start_slice:batch_end_slice+1,:,:] = model.predict(CTarrayNormBBslices[0:1,:,batch_start_slice:batch_end_slice+1,:,:])\n",
    "\n",
    "        else:\n",
    "            print(\"batch = \", j)\n",
    "            batch_end_slice = batch_end_slice\n",
    "            batch_start_slice = batch_end_slice - batch_size +1\n",
    "            print(\"start slice = \", batch_start_slice)\n",
    "            print(\"end slice = \", batch_end_slice)\n",
    "            print(\"end slice + 1 = \", batch_end_slice + 1)\n",
    "            BBpredict[0:1,:,batch_start_slice:batch_end_slice+1,:,:] = model.predict(CTarrayNormBBslices[0:1,:,batch_start_slice:batch_end_slice+1,:,:])\n",
    "            batch_end_slice = batch_end_slice - batch_size # ready for the next batch\n",
    "\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #fig = plt.figure(frameon=False,figsize=(18, 18))\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# def update(w = TestSlices-1):\n",
    "\n",
    "#     im1 = plt.imshow(np.fliplr(np.rot90(CTarrayNormBBslices[0,0,w,:,:],2)),cmap='gray')\n",
    "#     plt.clim(0.25,0.45)\n",
    " \n",
    "#     im2 = plt.imshow(np.fliplr(np.rot90(BBpredict[0,0,w,:,:],2)), alpha=.3)\n",
    "#     plt.clim(0.5,1.0)\n",
    "#     plt.show()\n",
    "    \n",
    "#     fig.canvas.draw_idle()\n",
    "\n",
    "# interact(update);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showslice = 90\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "# im1 = plt.imshow(np.fliplr(np.rot90(CTarrayNormBBslices[0,0,showslice,:,:],2)),cmap='gray')\n",
    "# plt.clim(0.25,0.45)\n",
    "\n",
    "# im2 = plt.imshow(np.fliplr(np.rot90(BBpredict[0,0,showslice,:,:],2)), alpha=.3)\n",
    "# plt.clim(0.5,1.0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Largest component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largestComponent():\n",
    "    \n",
    "    global BBpredictLabelled\n",
    "    \n",
    "    BBpredict3D = BBpredict[0,0,:,:,:]\n",
    "    np.putmask(BBpredict3D,BBpredict3D >= 0.5, 1)\n",
    "    np.putmask(BBpredict3D,BBpredict3D < 1, 0)\n",
    "    structure3D = np.ones((3, 3, 3), dtype=np.int) # a kind of filter applied to get the components\n",
    "    BBpredictLabelled, ncomponents = label(BBpredict3D, structure3D)\n",
    "    \n",
    "    Array_Components = np.zeros((2,ncomponents), dtype = int)\n",
    "    for component in range (1,ncomponents+1):\n",
    "        Array_Components[0,component -1] = component\n",
    "        Array_Components[1,component -1] = np.count_nonzero(BBpredictLabelled == component)\n",
    "    print(Array_Components)\n",
    "    \n",
    "    locmax = np.argmax(Array_Components, axis=1, out=None)\n",
    "    \n",
    "    BBpredictLabelled[BBpredictLabelled != Array_Components[0,locmax[1]]] = 0 # i.e. removes all other components\n",
    "    BBpredictLabelled[BBpredictLabelled > 0 ] = 1 # resets BB largest component to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BB to match CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBtoMatchCT():\n",
    "\n",
    "    global CTarrayFull\n",
    "    global BBpredictFull\n",
    "    global PETarrayFull\n",
    "\n",
    "    BBpredictFull = np.zeros((Slices, 512,512), dtype = int)\n",
    "    CTarrayFull = CTarray[0,0,:,:,:]\n",
    "    PETarrayFull = PETarrayNew[0,0,:,:,:]\n",
    "\n",
    "    BBpredictFull = np.zeros((Slices, 512,512), dtype = int)\n",
    "    \n",
    "    BBpredictFull[(BBinfSliceNo-1):(BBsupSliceNo),:,:] = BBpredictLabelled\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing CT to match PET dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resampleCT():\n",
    "    global CTarrayNewResize\n",
    "    global BBarrayNewResize\n",
    "    global BBarrayNewResizeOrig\n",
    "    \n",
    "    padextra = round((round((PETReconDiameter/CTReconDiameter)*ConstPixelDims_CT[0]) - ConstPixelDims_CT[0])/2)\n",
    "    padextra\n",
    "    \n",
    "    if padextra > 0:\n",
    "        CTarrayPad = np.pad(CTarrayFull, ((0,0),(padextra,padextra),(padextra,padextra)), mode = 'constant', constant_values = (-1000))\n",
    "        BBarrayPad = np.pad(BBpredictFull, ((0,0),(padextra,padextra),(padextra,padextra)), mode = 'constant', constant_values = (0))\n",
    "        print(\"padextra > 0\")\n",
    "\n",
    "    elif padextra == 0:\n",
    "        CTarrayPad = np.copy(CTarrayFull)\n",
    "        BBarrayPad = np.copy(BBpredictFull)\n",
    "        print(\"padextra = 0\")\n",
    "\n",
    "    else:\n",
    "        CTarrayPad = CTarrayFull[:, -padextra:padextra, -padextra:padextra]\n",
    "        BBarrayPad = BBpredictFull[:, -padextra:padextra, -padextra:padextra]\n",
    "        print(\"padextra < 0\")\n",
    "        \n",
    "    xyZoomFactor = (ConstPixelDims_PET[0]/ConstPixelDims_CT[0])*(CTReconDiameter/PETReconDiameter)\n",
    "    zZoomFactor = np.size(PETarray,2)/np.size(CTarray,2)\n",
    "\n",
    "    CTarrayNewResize = zoom(CTarrayPad, (zZoomFactor,xyZoomFactor, xyZoomFactor))\n",
    "    BBarrayNewResize = zoom(BBarrayPad, (zZoomFactor,xyZoomFactor, xyZoomFactor))\n",
    "    \n",
    "    BBarrayNewResizeOrig = np.copy(BBarrayNewResize)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PETinSUVunits():\n",
    "    global PETarrayNewSUVbw\n",
    "    \n",
    "    for filenameDCM in lstFilesDCM_PET:\n",
    "        dsPET = dicom.read_file(filenameDCM)\n",
    "        ds_Units = dsPET[0x0054,0x1001].value\n",
    "        ds_halfLife = dsPET[0x0054,0x0016][0][0x0018,0x1075].value \n",
    "        ds_PtWeight = dsPET.PatientWeight\n",
    "        ds_PtName = dsPET[0x10,0x10].value\n",
    "        ds_injectedDose = dsPET[0x0054,0x0016][0][0x0018,0x1074].value\n",
    "        ds_seriesDate = dsPET[0x0008,0x0021].value\n",
    "        ds_seriesTime = dsPET[0x0008,0x0031].value\n",
    "        ds_acquisitionDate = dsPET[0x0008,0x0022].value\n",
    "        ds_acquisitionTime = dsPET[0x0008,0x0032].value\n",
    "        ds_scanTime = dsPET[0x0008,0x0031].value\n",
    "        ds_startTime = dsPET[0x0054,0x0016][0][0x0018,0x1072].value\n",
    "        ds_rescaleSlope = dsPET[0x0028,0x1053].value\n",
    "        ds_rescaleIntercept = dsPET[0x0028,0x1052].value\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        seriesTimeFormat  = datetime.datetime.strptime(ds_seriesTime, \"%H%M%S\")\n",
    "    except:\n",
    "        seriesTimeFormat  = datetime.datetime.strptime(ds_seriesTime, \"%H%M%S.%f\")\n",
    "\n",
    "    try:\n",
    "        acquisitionTimeFormat  = datetime.datetime.strptime(ds_acquisitionTime, \"%H%M%S\")\n",
    "    except:\n",
    "        acquisitionTimeFormat  = datetime.datetime.strptime(ds_acquisitionTime, \"%H%M%S.%f\")\n",
    "        \n",
    "    try:\n",
    "        startTimeFormat  = datetime.datetime.strptime(ds_startTime, \"%H%M%S\") # if the time is like this 105600\n",
    "    except:\n",
    "        startTimeFormat  = datetime.datetime.strptime(ds_startTime, \"%H%M%S.%f\") # if the time is decimal like this 105600.00\n",
    "\n",
    "    try:\n",
    "        scanTimeFormat  = datetime.datetime.strptime(ds_scanTime, \"%H%M%S\")\n",
    "    except:\n",
    "        scanTimeFormat  = datetime.datetime.strptime(ds_scanTime, \"%H%M%S.%f\")\n",
    "\n",
    "\n",
    "    decaytime = (scanTimeFormat - startTimeFormat).total_seconds()\n",
    "    \n",
    "    DecayedDose = ds_injectedDose * pow(2,(-decaytime/ds_halfLife))\n",
    "    \n",
    "    SUVbwScaleFactor = (ds_PtWeight * 1000) / DecayedDose\n",
    "    \n",
    "    PETarrayNewSUVbw = ((PETarrayFull) + ds_rescaleIntercept) * SUVbwScaleFactor\n",
    "\n",
    "    print(np.shape(CTarrayNewResize))\n",
    "    print(np.shape(PETarrayNewSUVbw))\n",
    "    print(np.shape(BBarrayNewResize))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peripheral PET removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we choose a value of SUV that we want to threshold\n",
    "## We then remove thresholded regions outside, and on periphery of, the bowel segmentation\n",
    "\n",
    "def PeripheralPETremoval():\n",
    "    global BBarrayNewResize\n",
    "    \n",
    "    \n",
    "    SUVthreshold = 4\n",
    "    PETthresh = np.copy(PETarrayNewSUVbw)\n",
    "    np.putmask(PETthresh,PETthresh < SUVthreshold, 0)\n",
    "    np.putmask(PETthresh,PETthresh >=  SUVthreshold, 1)\n",
    "    structurePET3D = np.ones((3, 3, 3), dtype=np.int) # a kind of filter applied to get the components\n",
    "    PETLabelled, nPETcomponents = label(PETthresh, structurePET3D)\n",
    "\n",
    "    labelvalue = nPETcomponents+2 # sets a unique label to use for later\n",
    "\n",
    "    for PETcomponent in range (1,nPETcomponents+1): #for each component of PET image greater than threshold\n",
    "\n",
    "        print(\"PETcomponent \", PETcomponent)\n",
    "        print(\"BB size = \", np.count_nonzero(BBarrayNewResize == 1))\n",
    "\n",
    "        n = np.count_nonzero(PETLabelled == PETcomponent)\n",
    "        print(\"size of component (n) = \", n)\n",
    "\n",
    "        # make array with only that component and set value = unique label\n",
    "        arrayComponent = np.copy(PETLabelled)\n",
    "        np.putmask(arrayComponent, arrayComponent == PETcomponent, (labelvalue))\n",
    "        np.putmask(arrayComponent, arrayComponent != (labelvalue), 0)\n",
    "\n",
    "        m = np.count_nonzero(arrayComponent == (labelvalue))\n",
    "        print(\"size of component (m) = \", m)\n",
    "\n",
    "        # multiply component arrat with binary BBB\n",
    "        # if component is totally within the BB then all values maintain their label\n",
    "        # if component is totally outside the BB then all values maintain become 0\n",
    "        # if component is on edge of BB then only some of the elements will retain their labelled value\n",
    "        arraynew = np.multiply(arrayComponent,BBarrayNewResize)\n",
    "\n",
    "        mstar = np.count_nonzero(arraynew == (labelvalue))\n",
    "        print(\"mstar = \", mstar)\n",
    "\n",
    "        if mstar == n:     # i.e. all elements maintained their label\n",
    "\n",
    "            print(\"************************* INSIDE\")\n",
    "\n",
    "        if mstar == 0:     # i.e. all elements were converted to 0\n",
    "            print(\"**************************OUTSIDE\")\n",
    "\n",
    "        if mstar > 0 and mstar < n:     # some of the elements were converted to 0, the rest maintained value \n",
    "            print(\"*********************************PERIPHERY**\")\n",
    "            np.putmask(arraynew, arraynew > 0, 1)\n",
    "            BBarrayNewResize = BBarrayNewResize - arraynew\n",
    "            BBsize = np.count_nonzero(BBarrayNewResize == 1)\n",
    "            print(\"New BB size = \", BBsize)\n",
    "\n",
    "        print(\"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUV extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUVextraction():\n",
    "    \n",
    "    SUVinBB = np.multiply(BBarrayNewResize,PETarrayNewSUVbw)\n",
    "    np.putmask(SUVinBB,SUVinBB == 0, np.nan)\n",
    "    \n",
    "    MeanValue = np.nanmean(SUVinBB)\n",
    "    print(\"Mean SUV = \", MeanValue)\n",
    "    MedianValue = np.nanmedian(SUVinBB)\n",
    "    print(\"Median SUV = \", MedianValue)\n",
    "    MaxValue = np.nanmax(SUVinBB)\n",
    "    print(\"Max SUV = \", MaxValue)\n",
    "    NinetyFive_Value = np.nanpercentile(SUVinBB, 95)\n",
    "    print(\"95 percentile SUV = \", NinetyFive_Value)\n",
    "    NinetyNine_Value = np.nanpercentile(SUVinBB, 99)\n",
    "    print(\"99 percentile SUV = \", NinetyNine_Value)\n",
    "    \n",
    "    SUVinBBflat = np.ndarray.flatten(SUVinBB)\n",
    "    plt.hist(SUVinBBflat, bins=30, range = (0,3))\n",
    "    plt.title(\"Histogram\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofDICOMfiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadDicoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayMods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictBB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestComponent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBtoMatchCT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampleCT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PETinSUVunits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PeripheralPETremoval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUVextraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliceToPlot = 67\n",
    "\n",
    "print(sliceToPlot)\n",
    "print(sliceToPlot-BBinfSliceNo)\n",
    "fig1 = plt.figure(figsize=(6, 6))\n",
    "\n",
    "im1 = plt.imshow(np.fliplr(np.rot90(CTarrayNewResize[sliceToPlot-1,:,:],2)),cmap='gray')\n",
    "plt.clim(-300,500)\n",
    "\n",
    "#im2 = CPredict = plt.contour(np.fliplr(np.rot90(BBarrayNewResizeOrig[sliceToPlot-1,:,:],2)), [1], linestyles = 'solid', colors = ['yellow'])\n",
    "im2 = plt.imshow(np.fliplr(np.rot90(BBarrayNewResizeOrig[sliceToPlot-1,:,:],2)),alpha=0.2, cmap='Reds') # transparency is alpha\n",
    "#im2 = plt.colorbar()\n",
    "\n",
    "im3 = CPredict = plt.contour(np.fliplr(np.rot90(BBarrayNewResize[sliceToPlot-1,:,:],2)), [1], linestyles = 'solid', colors = ['red'])\n",
    "#im3 = plt.imshow(np.fliplr(np.rot90(BBarrayNewResize[sliceToPlot-1,:,:],2)),alpha=0.3) # transparency is alpha\n",
    "#im3 = plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = CPredict = plt.contour(AllDoseData128[0,0,:,:,showslice], [1], linestyles = 'solid', colors = ['yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflowChris)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
